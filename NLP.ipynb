{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c189592a-64d1-4b6c-a51a-2172d2ddac48",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb4b41-436c-4721-8597-3947d6b8ba90",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b2097-d5dd-461d-8517-8714b65352c3",
   "metadata": {},
   "source": [
    " #### Tokenization, in the realm of Natural Language Processing (NLP) and machine learning, refers to the process of converting a sequence of text into smaller parts, known as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b8b895-7303-43b8-9658-07b07513701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/sijan/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /home/sijan/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /home/sijan/.local/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: click in /home/sijan/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/sijan/.local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f0b825-e26f-4f3c-9f43-6268442f7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hello, my name is Sijan.\n",
    "Hi there! beautiful's world.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2d98d3-1fb4-4e6d-ab49-970218091732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Sijan.\n",
      "Hi there! beautiful's world.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef35fec-d45e-4e29-8457-73532fd48ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## Paragraph --> Sentences\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02f1e37-5cd3-42b8-9e93-808caab14ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sijan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ca3719-b9f0-4bc6-b467-6763b45e216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b33a7a71-77a7-4d56-80f6-b270cd38ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, my name is Sijan.', 'Hi there!', \"beautiful's world.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34189944-aca9-4954-bd6b-e0bb40eeff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Sijan.\n",
      "Hi there!\n",
      "beautiful's world.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff2d3885-98da-4d4a-b2e3-3a6cc9936019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## Paragraph-->words\n",
    "## sentence-->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb10dab-6dc7-4f5d-8d77-19b5f0a9988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Sijan',\n",
       " '.',\n",
       " 'Hi',\n",
       " 'there',\n",
       " '!',\n",
       " 'beautiful',\n",
       " \"'s\",\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4354b748-dd6d-4414-b4c5-02f5c8029151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'my', 'name', 'is', 'Sijan', '.']\n",
      "['Hi', 'there', '!']\n",
      "['beautiful', \"'s\", 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "091059c2-d239-4f17-be17-621d104f2d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Sijan',\n",
       " '.',\n",
       " 'Hi',\n",
       " 'there',\n",
       " '!',\n",
       " 'beautiful',\n",
       " \"'\",\n",
       " 's',\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65b8afd9-8335-43f3-921a-534e0075be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b2a5db-b596-4f14-8fea-dceee3395e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d69a96f0-b610-4b20-acbd-ca3b942f8f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Sijan.',\n",
       " 'Hi',\n",
       " 'there',\n",
       " '!',\n",
       " 'beautiful',\n",
       " \"'s\",\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea595af-945b-4e99-8c11-583ab02a40ea",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b6a62-75a9-4769-a4cf-997f4c1045e4",
   "metadata": {},
   "source": [
    "#### Stemming, in Natural Language Processing (NLP), refers to the process of reducing a word to its word stem that affixes to suffixes and prefixes or the roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d817a69-18c1-4039-b249-2be2cc88ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115eac6-c1eb-4773-8203-fddfe6e41b8b",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce96c573-d49a-4bdd-9222-cb4e72b19f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a45d5e1-eb35-464e-8ef5-cd65107ece73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3750126-1af1-4cf6-b6bf-cf9301d387e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "writes--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalized--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63d990c4-29d2-4bf7-834d-7c1bbb2d7007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e65134a-e257-46af-91de-fc72704cfb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d0e6cc-e238-4098-ab7b-656b1ec7b7e3",
   "metadata": {},
   "source": [
    "### RegexpStemmer Class\n",
    "##### NLTK has RegexpStemmer Class with the help of which we can easily implement Regular Expression Stemmer Algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5677134f-89c9-495b-ab2d-8a04269dfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ac581cd-4fb1-45a3-a78a-e3621a7c5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer(\"ing$|s$|e$|able$\", min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83975e9c-8014-47d5-99dc-9f04dc1f7bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78bdb75b-fa46-4c92-88f0-a7b450044b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clas'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7542649-2455-46ad-ba19-4dd2434d2d24",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    "#### better than PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56a8b020-cd55-4a98-95e0-11053c2d8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90895a1a-f804-4cee-b983-30595e0bdcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22f9af09-5969-4d5a-8575-a26c8a3255b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "writes--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalized--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde1284-e50a-46cf-bab0-ae401c7b0fcf",
   "metadata": {},
   "source": [
    "#### Why snowball stemmer better than porter stemmer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91a8b1b5-fdc0-47fc-be47-1fc0f237d0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"), stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92fbc6d7-5832-4b85-b293-632509eda3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"fairly\"), snowball_stemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4bdb62-e791-43c2-8b37-74458ec4b919",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fa882-71b2-4c9a-a0d0-33c8a331d1dc",
   "metadata": {},
   "source": [
    "### Wordnet Lemmatizer\n",
    "#### Lemmatization technique is like stemming. The output we will get after lemmatization is called \"lemma\", which is a root word rather root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
    "\n",
    "#### NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94329f73-05dc-4f6a-900a-7eacbbefdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb1da22d-260d-41b6-9c57-2d024344b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d613b13b-71a6-44cc-8c62-1e2c22811af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sijan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30d4a3d0-fb28-4fa9-a216-88e1ee083766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS- Noun-n\n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "lemmatizer.lemmatize(\"going\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9206a4de-8853-4200-8c77-483bba8b0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "626d166b-9ecc-4864-9351-e361f1ae3bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eat\n",
      "writing--->write\n",
      "writes--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->history\n",
      "finally--->finally\n",
      "finalized--->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+lemmatizer.lemmatize(word, pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "515a71aa-1f38-4d32-bd56-143c0c3d3bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'sportingly')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\",pos=\"v\"), lemmatizer.lemmatize(\"sportingly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a259a8a-843b-479f-b96b-54a3f6a5cd02",
   "metadata": {},
   "source": [
    "## Stopwords with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c27fb97d-18a9-435e-bb71-dae559e16f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacking\n",
    "paragraph = '''A commonly used hacking definition is the act of compromising digital devices and networks through unauthorized access to an account or computer system. Hacking is not always a malicious act, but it is most commonly associated with illegal activity and data theft by cyber criminals. \n",
    "\n",
    "But what is hacking in a cyber security context? \n",
    "\n",
    "Hacking in cyber security refers to the misuse of devices like computers, smartphones, tablets, and networks to cause damage to or corrupt systems, gather information on users, steal data and documents, or disrupt data-related activity.\n",
    "\n",
    "A traditional view of hackers is a lone rogue programmer who is highly skilled in coding and modifying computer software and hardware systems. But this narrow view does not cover the true technical nature of hacking. Hackers are increasingly growing in sophistication, using stealthy attack methods designed to go completely unnoticed by cybersecurity software and IT teams. They are also highly skilled in creating attack vectors that trick users into opening malicious attachments or links and freely giving up their sensitive personal data.\n",
    "\n",
    "As a result, modern-day hacking involves far more than just an angry kid in their bedroom. It is a multibillion-dollar industry with extremely sophisticated and successful techniques.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a296e918-21a6-491e-a268-5284012ee23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "624e6776-41fd-4792-bfda-875a9633e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7072f22c-9cd9-4692-ad29-8f9473bd2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sijan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2de29aaf-bddb-454e-bbbe-b4bebebfe86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "431b9b7c-f08f-467d-a1ee-cbc6f8448774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8150c065-a7fd-4a47-b6d1-93050ec0e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd79436c-2c30-4f47-91a4-0cb82e9e5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a437958f-405e-4bff-83e0-efddf4992d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f19a3201-b207-4da1-998a-576b531613b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2615547d-3616-4e6a-b6f3-59dda0eacfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Stopwords and filter And then apply Stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i] = ' '.join(words) ## converting all the list of words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f4e0b9ef-ec78-498d-bb48-8a73044a12ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a commonli use hack definit act compromis digit devic network unauthor access account comput system .',\n",
       " 'hack alway malici act , commonli associ illeg activ data theft cyber crimin .',\n",
       " 'but hack cyber secur context ?',\n",
       " 'hack cyber secur refer misus devic like comput , smartphon , tablet , network caus damag corrupt system , gather inform user , steal data document , disrupt data-rel activ .',\n",
       " 'a tradit view hacker lone rogu programm highli skill code modifi comput softwar hardwar system .',\n",
       " 'but narrow view cover true technic natur hack .',\n",
       " 'hacker increasingli grow sophist , use stealthi attack method design go complet unnot cybersecur softwar it team .',\n",
       " 'they also highli skill creat attack vector trick user open malici attach link freeli give sensit person data .',\n",
       " 'as result , modern-day hack involv far angri kid bedroom .',\n",
       " 'it multibillion-dollar industri extrem sophist success techniqu .']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ada46f8b-635a-4fc6-a235-7c6d6ecfc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Stopwords and filter And then apply Stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [snowball_stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i] = ' '.join(words) ## converting all the list of words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3311402a-fef2-40d4-9097-0cce93fba982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a common use hack definit act compromis digit devic network unauthor access account comput system .',\n",
       " 'hack alway malici act , common associ illeg activ data theft cyber crimin .',\n",
       " 'but hack cyber secur context ?',\n",
       " 'hack cyber secur refer misus devic like comput , smartphon , tablet , network caus damag corrupt system , gather inform user , steal data document , disrupt data-rel activ .',\n",
       " 'a tradit view hacker lone rogu programm high skill code modifi comput softwar hardwar system .',\n",
       " 'but narrow view cover true technic natur hack .',\n",
       " 'hacker increas grow sophist , use stealthi attack method design go complet unnot cybersecur softwar it team .',\n",
       " 'they also high skill creat attack vector trick user open malici attach link freeli give sensit person data .',\n",
       " 'as result , modern-day hack involv far angri kid bedroom .',\n",
       " 'it multibillion-dollar industri extrem sophist success techniqu .']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c4ac69c-e05b-48a9-bcc2-f6163fc902cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "641f1464-ad03-4c16-831c-e1b97987fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Stopwords and filter And then apply Stemming\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word.lower(), pos=\"v\") for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    sentences[i] = ' '.join(words) ## converting all the list of words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63d3bb74-f308-4ab6-99a0-ea8a419a9199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a commonly use hack definition act compromise digital devices network unauthorized access account computer system .',\n",
       " 'hack always malicious act , commonly associate illegal activity data theft cyber criminals .',\n",
       " 'but hack cyber security context ?',\n",
       " 'hack cyber security refer misuse devices like computers , smartphones , tablets , network cause damage corrupt systems , gather information users , steal data document , disrupt data-related activity .',\n",
       " 'a traditional view hackers lone rogue programmer highly skilled cod modify computer software hardware systems .',\n",
       " 'but narrow view cover true technical nature hack .',\n",
       " 'hackers increasingly grow sophistication , use stealthy attack methods design go completely unnoticed cybersecurity software it team .',\n",
       " 'they also highly skilled create attack vectors trick users open malicious attachments link freely give sensitive personal data .',\n",
       " 'as result , modern-day hack involve far angry kid bedroom .',\n",
       " 'it multibillion-dollar industry extremely sophisticate successful techniques .']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e6bfaa4-292b-47ea-a497-bddc5fee04c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'techniques'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"techniques\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a6680-7fa7-4939-8f86-86113affa1bf",
   "metadata": {},
   "source": [
    "## Parts of Speech (pos) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b101a55-6363-4845-8bb7-7b09678d0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19fabaa8-2212-45e6-bfc9-639247399943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de672682-b9c7-4b3f-98d3-59de6c776305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A commonly used hacking definition is the act of compromising digital devices and networks through unauthorized access to an account or computer system.',\n",
       " 'Hacking is not always a malicious act, but it is most commonly associated with illegal activity and data theft by cyber criminals.',\n",
       " 'But what is hacking in a cyber security context?',\n",
       " 'Hacking in cyber security refers to the misuse of devices like computers, smartphones, tablets, and networks to cause damage to or corrupt systems, gather information on users, steal data and documents, or disrupt data-related activity.',\n",
       " 'A traditional view of hackers is a lone rogue programmer who is highly skilled in coding and modifying computer software and hardware systems.',\n",
       " 'But this narrow view does not cover the true technical nature of hacking.',\n",
       " 'Hackers are increasingly growing in sophistication, using stealthy attack methods designed to go completely unnoticed by cybersecurity software and IT teams.',\n",
       " 'They are also highly skilled in creating attack vectors that trick users into opening malicious attachments or links and freely giving up their sensitive personal data.',\n",
       " 'As a result, modern-day hacking involves far more than just an angry kid in their bedroom.',\n",
       " 'It is a multibillion-dollar industry with extremely sophisticated and successful techniques.']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fffe0dfe-5053-40c6-884c-586807c157ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sijan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8be515c1-3c3d-4858-8e44-fbb8cc709a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('commonly', 'RB'), ('used', 'VBN'), ('hacking', 'VBG'), ('definition', 'NN'), ('act', 'NN'), ('compromising', 'VBG'), ('digital', 'JJ'), ('devices', 'NNS'), ('networks', 'NNS'), ('unauthorized', 'JJ'), ('access', 'NN'), ('account', 'NN'), ('computer', 'NN'), ('system', 'NN'), ('.', '.')]\n",
      "[('Hacking', 'VBG'), ('always', 'RB'), ('malicious', 'JJ'), ('act', 'NN'), (',', ','), ('commonly', 'RB'), ('associated', 'JJ'), ('illegal', 'JJ'), ('activity', 'NN'), ('data', 'NNS'), ('theft', 'NN'), ('cyber', 'NN'), ('criminals', 'NNS'), ('.', '.')]\n",
      "[('But', 'CC'), ('hacking', 'VBG'), ('cyber', 'JJ'), ('security', 'NN'), ('context', 'NN'), ('?', '.')]\n",
      "[('Hacking', 'VBG'), ('cyber', 'JJ'), ('security', 'NN'), ('refers', 'NNS'), ('misuse', 'VBP'), ('devices', 'NNS'), ('like', 'IN'), ('computers', 'NNS'), (',', ','), ('smartphones', 'NNS'), (',', ','), ('tablets', 'NNS'), (',', ','), ('networks', 'NNS'), ('cause', 'VBP'), ('damage', 'NN'), ('corrupt', 'JJ'), ('systems', 'NNS'), (',', ','), ('gather', 'JJ'), ('information', 'NN'), ('users', 'NNS'), (',', ','), ('steal', 'JJ'), ('data', 'NN'), ('documents', 'NNS'), (',', ','), ('disrupt', 'JJ'), ('data-related', 'JJ'), ('activity', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('traditional', 'JJ'), ('view', 'NN'), ('hackers', 'NNS'), ('lone', 'VBP'), ('rogue', 'JJ'), ('programmer', 'NN'), ('highly', 'RB'), ('skilled', 'VBD'), ('coding', 'VBG'), ('modifying', 'VBG'), ('computer', 'NN'), ('software', 'NN'), ('hardware', 'NN'), ('systems', 'NNS'), ('.', '.')]\n",
      "[('But', 'CC'), ('narrow', 'JJ'), ('view', 'NN'), ('cover', 'NN'), ('true', 'JJ'), ('technical', 'JJ'), ('nature', 'NN'), ('hacking', 'NN'), ('.', '.')]\n",
      "[('Hackers', 'NNS'), ('increasingly', 'RB'), ('growing', 'VBG'), ('sophistication', 'NN'), (',', ','), ('using', 'VBG'), ('stealthy', 'JJ'), ('attack', 'NN'), ('methods', 'NNS'), ('designed', 'VBN'), ('go', 'VBP'), ('completely', 'RB'), ('unnoticed', 'JJ'), ('cybersecurity', 'NN'), ('software', 'NN'), ('IT', 'NNP'), ('teams', 'VBZ'), ('.', '.')]\n",
      "[('They', 'PRP'), ('also', 'RB'), ('highly', 'RB'), ('skilled', 'JJ'), ('creating', 'VBG'), ('attack', 'NN'), ('vectors', 'NNS'), ('trick', 'VBP'), ('users', 'NNS'), ('opening', 'VBG'), ('malicious', 'JJ'), ('attachments', 'NNS'), ('links', 'VBZ'), ('freely', 'RB'), ('giving', 'VBG'), ('sensitive', 'JJ'), ('personal', 'JJ'), ('data', 'NNS'), ('.', '.')]\n",
      "[('As', 'IN'), ('result', 'NN'), (',', ','), ('modern-day', 'JJ'), ('hacking', 'NN'), ('involves', 'VBZ'), ('far', 'RB'), ('angry', 'JJ'), ('kid', 'NN'), ('bedroom', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), ('multibillion-dollar', 'JJ'), ('industry', 'NN'), ('extremely', 'RB'), ('sophisticated', 'JJ'), ('successful', 'JJ'), ('techniques', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## we will find the pos tag\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    # sentences[i] = \" \".join(words) #converting all the list of words into sentences\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c49774ac-aa59-421d-8539-3ff0e43b6a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Taj', 'NNP'),\n",
       " ('Mahal', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('Monument', 'NN')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"Taj Mahal is a beautiful Monument\".split()\n",
    "nltk.pos_tag(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d82ceab8-96a8-4dc7-ba2d-a72cfc9622a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taj', 'Mahal', 'is', 'a', 'beautiful', 'Monument']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Taj Mahal is a beautiful Monument\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe3244-301b-49b6-82e2-dc00cff6a15c",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fad388f4-51c0-42e3-af3c-9599af060ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''The Effiel Tower was built from 1887 to 1889 by French engineer Gustave Effiel, whose company specialized in building metal frameworks and structures.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98e91c5c-3569-40c7-8008-4747078e0187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Effiel Tower was built from 1887 to 1889 by French engineer Gustave Effiel, whose company specialized in building metal frameworks and structures.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc2085f3-1d77-4719-a083-1cd69b23d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "words = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a94e4c76-ae72-493e-b09f-b7d81f3949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_elements = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8104af67-d955-4a84-b96c-be3ab3286d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/sijan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd573f51-bfcf-4afc-809f-42e055176161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/sijan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b1218191-12ee-45f4-8512-f120369305b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(tag_elements).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12c1d0-05db-410a-95cd-fe6bfd086f86",
   "metadata": {},
   "source": [
    "# Word2vec Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecb6ea0-29be-49bb-8208-e45abeff60dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m220.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.0.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 KB\u001b[0m \u001b[31m195.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /home/sijan/.local/lib/python3.10/site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/lib/python3/dist-packages (from gensim) (1.8.0)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 KB\u001b[0m \u001b[31m89.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m162.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.1 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32710b0e-b214-46d3-bc63-c9db41d2a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43775dfc-5e5f-457a-bfc0-5710ee056fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70d35d4-8100-49d3-8b66-6438845f2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0006af92-0948-448c-b9f5-7de6b34dc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f74713b-8421-4814-8550-bff438d256c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = wv[\"king\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b28fe0-939d-48c4-a19f-5b85902ca337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7003e6c-9046-4ffa-9612-b83119af5f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ebb7d-3282-4b0c-a62b-c0184e2124a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"cricket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a5554-fa4a-41ec-9762-e49783e11963",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633fcca0-7004-4ca9-83bf-dfd4abf1e61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5354152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"hockey\", \"sports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e803665b-b331-4acc-b215-f714bc5ac38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = wv[\"king\"]-wv[\"man\"]+wv[\"woman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde4165d-ea6c-492c-a2f2-5bdee09bfefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.29687500e-02, -1.78222656e-01, -1.29089355e-01,  1.15234375e-01,\n",
       "        2.68554688e-03, -1.02294922e-01,  1.95800781e-01, -1.79504395e-01,\n",
       "        1.95312500e-02,  4.09919739e-01, -3.68164062e-01, -3.96484375e-01,\n",
       "       -1.56738281e-01,  1.46484375e-03, -9.30175781e-02, -1.16455078e-01,\n",
       "       -5.51757812e-02, -1.07574463e-01,  7.91015625e-02,  1.98974609e-01,\n",
       "        2.38525391e-01,  6.34002686e-02, -2.17285156e-02,  0.00000000e+00,\n",
       "        4.72412109e-02, -2.17773438e-01, -3.44726562e-01,  6.37207031e-02,\n",
       "        3.16406250e-01, -1.97631836e-01,  8.59375000e-02, -8.11767578e-02,\n",
       "       -3.71093750e-02,  3.15551758e-01, -3.41796875e-01, -4.68750000e-02,\n",
       "        9.76562500e-02,  8.39843750e-02, -9.71679688e-02,  5.17578125e-02,\n",
       "       -5.00488281e-02, -2.20947266e-01,  2.29492188e-01,  1.26403809e-01,\n",
       "        2.49023438e-01,  2.09960938e-02, -1.09863281e-01,  5.81054688e-02,\n",
       "       -3.35693359e-02,  1.29577637e-01,  2.41699219e-02,  3.48129272e-02,\n",
       "       -2.60009766e-01,  2.42309570e-01, -3.21777344e-01,  1.45416260e-02,\n",
       "       -1.59179688e-01, -8.37402344e-02,  1.65039062e-01,  1.58691406e-03,\n",
       "        3.09570312e-01,  3.16406250e-01,  7.38525391e-03,  2.41210938e-01,\n",
       "        4.90722656e-02, -9.86328125e-02,  2.90527344e-02,  1.49414062e-01,\n",
       "       -4.83398438e-02,  2.35595703e-01,  2.21191406e-01,  1.25488281e-01,\n",
       "       -1.38671875e-01,  1.54296875e-01,  7.18994141e-02,  1.29882812e-01,\n",
       "       -1.05712891e-01,  6.00585938e-02,  3.14697266e-01,  1.09619141e-01,\n",
       "        8.49609375e-02,  7.71484375e-02, -2.17285156e-02,  6.11572266e-02,\n",
       "       -1.89941406e-01,  2.07519531e-01, -1.63085938e-01,  1.13525391e-01,\n",
       "        2.01171875e-01,  6.06689453e-02,  1.27929688e-01, -3.11279297e-01,\n",
       "       -2.80151367e-01, -1.55883789e-01,  4.15039062e-02,  9.87854004e-02,\n",
       "        1.69555664e-01, -3.49121094e-02,  2.08496094e-01, -9.89990234e-02,\n",
       "        4.39453125e-03, -7.27539062e-02, -4.24804688e-02, -4.09179688e-01,\n",
       "       -2.76367188e-01,  1.64062500e-01, -5.57617188e-01, -2.02199936e-01,\n",
       "        2.12158203e-01, -9.81445312e-02,  2.30773926e-01,  2.75878906e-01,\n",
       "        1.68092728e-01, -4.50439453e-02,  1.71615601e-01, -3.77075195e-01,\n",
       "       -3.52478027e-03, -3.01513672e-01,  1.74224854e-01,  3.30078125e-01,\n",
       "        2.00683594e-01,  1.17736816e-01, -1.37695312e-01, -1.07421875e-01,\n",
       "        8.61816406e-02,  1.06445312e-01,  1.44531250e-01,  3.05175781e-03,\n",
       "        1.80664062e-02,  3.73535156e-02,  7.32421875e-03,  1.32812500e-01,\n",
       "        9.61914062e-02,  3.35998535e-01,  1.81152344e-01,  2.40905762e-01,\n",
       "       -8.49609375e-02, -1.10107422e-01,  2.11914062e-01,  5.85937500e-03,\n",
       "        1.62109375e-01, -4.15527344e-01,  1.39160156e-01,  1.01562500e-01,\n",
       "        1.44531250e-01, -1.09375000e-01,  4.88281250e-02,  6.15234375e-02,\n",
       "       -1.69921875e-01,  3.28369141e-02,  5.56640625e-02,  1.47460938e-01,\n",
       "       -2.24609375e-02, -2.73925781e-01, -2.81982422e-01, -1.39160156e-01,\n",
       "       -1.81884766e-01,  9.33532715e-02,  1.21093750e-01, -5.37109375e-03,\n",
       "       -1.87500000e-01,  3.05175781e-04,  5.52734375e-01, -9.71679688e-02,\n",
       "       -1.81640625e-01, -1.51855469e-01,  7.76367188e-02, -2.38281250e-01,\n",
       "       -2.63977051e-02,  2.25555420e-01, -3.02734375e-01,  1.34765625e-01,\n",
       "        3.23242188e-01,  1.25976562e-01,  3.51562500e-02, -2.04345703e-01,\n",
       "        2.96142578e-01,  1.03149414e-01, -4.76074219e-03,  1.69189453e-01,\n",
       "       -3.50585938e-01,  2.46887207e-02, -3.90502930e-01, -2.70507812e-01,\n",
       "        1.85241699e-02,  1.04492188e-01,  2.84179688e-01,  1.35009766e-01,\n",
       "       -5.95703125e-02,  1.88232422e-01,  8.88214111e-02,  3.24707031e-02,\n",
       "       -8.98437500e-02,  5.45043945e-02,  5.65185547e-02,  1.56860352e-01,\n",
       "       -9.70458984e-03, -7.08007812e-02,  5.71289062e-02, -3.08837891e-01,\n",
       "       -1.91894531e-01,  4.83398438e-02,  5.22460938e-02, -1.59667969e-01,\n",
       "       -4.49218750e-02, -7.37304688e-02,  5.51757812e-02,  2.12402344e-01,\n",
       "        2.05322266e-01, -2.73437500e-02,  7.86132812e-02,  3.19091797e-01,\n",
       "       -1.56982422e-01, -3.92822266e-01,  4.00390625e-02,  9.93652344e-02,\n",
       "       -1.97372437e-02, -8.25195312e-02,  2.53906250e-02,  3.10668945e-02,\n",
       "       -3.63769531e-02,  1.48925781e-02,  2.20703125e-01, -5.98144531e-02,\n",
       "        6.15234375e-02, -7.14111328e-02, -4.00390625e-02, -1.03515625e-01,\n",
       "        9.22851562e-02,  2.71789551e-01, -2.30224609e-01, -2.62695312e-01,\n",
       "       -5.61523438e-01,  1.38549805e-02,  1.09863281e-01,  7.22656250e-02,\n",
       "        4.58984375e-02, -3.31802368e-02, -8.03833008e-02, -6.10351562e-03,\n",
       "        2.09960938e-01, -3.86840820e-01,  1.44645691e-01,  8.05664062e-02,\n",
       "        2.96264648e-01, -1.17187500e-02, -2.34680176e-01,  1.32019043e-01,\n",
       "        2.53906250e-01, -2.46826172e-01,  1.03759766e-01,  1.14013672e-01,\n",
       "        1.71875000e-01, -5.61523438e-03,  2.05078125e-01,  6.34765625e-02,\n",
       "       -4.51293945e-01, -2.26562500e-01, -1.03027344e-01, -1.31469727e-01,\n",
       "        3.75976562e-02,  2.70996094e-01, -2.39257812e-01,  3.80859375e-02,\n",
       "       -3.90625000e-02, -9.42382812e-02,  8.30078125e-03,  7.03125000e-02,\n",
       "        2.75390625e-01,  3.31542969e-01, -1.07421875e-02,  3.72192383e-01,\n",
       "       -1.24511719e-01,  1.94335938e-01, -1.35620117e-01, -3.09570312e-01,\n",
       "       -2.36328125e-01, -1.26953125e-02, -2.76855469e-01,  1.57714844e-01,\n",
       "        3.07617188e-01, -2.32910156e-01,  3.25439453e-01,  1.36718750e-02,\n",
       "        1.99462891e-01, -2.61840820e-02, -8.08105469e-02, -7.50732422e-02,\n",
       "       -4.11109924e-02,  1.95556641e-01, -5.64270020e-02, -2.79296875e-01,\n",
       "       -2.75390625e-01, -4.04296875e-01, -1.75781250e-02, -5.85937500e-03,\n",
       "       -7.71484375e-02,  1.33789062e-01,  2.36816406e-01,  2.01538086e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69263c7-9c75-4fa9-8d27-6f69316f3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374a0a3-03bc-4ffc-a3c8-e253ba72381d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
